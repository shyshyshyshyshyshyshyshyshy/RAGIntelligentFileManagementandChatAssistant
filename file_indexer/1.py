# test_upload_mode.py
import os
import sys
import time
import json
import requests
import hashlib
from datetime import datetime
from dotenv import load_dotenv
import logging

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('upload_test.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class Config:
    """é…ç½®ç±»"""
    DIFY_BASE_URL = os.getenv('DIFY_BASE_URL', 'http://localhost').rstrip('/')
    DATASET_API_KEY = os.getenv('DIFY_API_KEY', 'dataset-zqGccO9VowfmI7bPG6opOh5C')
    
    # çŸ¥è¯†åº“é…ç½®
    PARENT_CHILD_KB_ID = os.getenv('PARENT_CHILD_KB_ID', '1388750e-551b-4084-b699-17091a5b8364')
    TXT_KNOWLEDGE_BASE_ID = os.getenv('DIFY_KNOWLEDGE_BASE_ID', '1f0cc924-cba1-4113-83eb-dca99b0a31f9')
    
    API_TIMEOUT = int(os.getenv('API_TIMEOUT', '60'))

config = Config()

class UploadTester:
    """ä¸Šä¼ æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.base_url = config.DIFY_BASE_URL
        self.api_key = config.DATASET_API_KEY
    
    def test_upload_modes(self, file_path):
        """æµ‹è¯•ä¸åŒçš„ä¸Šä¼ æ¨¡å¼"""
        file_name = os.path.basename(file_path)
        logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯•æ–‡ä»¶ä¸Šä¼ æ¨¡å¼: {file_name}")
        
        # å®šä¹‰ä¸åŒçš„ä¸Šä¼ ç­–ç•¥
        strategies = [
            {
                "name": "å®Œå…¨ç©ºé…ç½®ï¼ˆæœ€å°é…ç½®ï¼‰",
                "data": {"name": file_name},
                "description": "ä¸æŒ‡å®šä»»ä½•å¤„ç†è§„åˆ™ï¼Œè®©Difyä½¿ç”¨çŸ¥è¯†åº“é»˜è®¤è®¾ç½®"
            },
            {
                "name": "ä»…è‡ªåŠ¨æ¨¡å¼",
                "data": {
                    "name": file_name,
                    "process_rule": json.dumps({"mode": "automatic"})
                },
                "description": "åªæŒ‡å®šè‡ªåŠ¨æ¨¡å¼ï¼Œä¸è®¾ç½®å…·ä½“è§„åˆ™"
            },
            {
                "name": "è‡ªåŠ¨æ¨¡å¼+ç©ºè§„åˆ™",
                "data": {
                    "name": file_name,
                    "process_rule": json.dumps({"mode": "automatic", "rules": {}})
                },
                "description": "è‡ªåŠ¨æ¨¡å¼+ç©ºè§„åˆ™ï¼Œè®©Difyè‡ªåŠ¨é€‰æ‹©"
            },
            {
                "name": "é«˜è´¨é‡ç´¢å¼•",
                "data": {
                    "name": file_name,
                    "indexing_technique": "high_quality"
                },
                "description": "åªæŒ‡å®šé«˜è´¨é‡ç´¢å¼•"
            },
            {
                "name": "å®Œæ•´é…ç½®ï¼ˆè‡ªåŠ¨+é«˜è´¨é‡ï¼‰",
                "data": {
                    "name": file_name,
                    "process_rule": json.dumps({"mode": "automatic", "rules": {}}),
                    "indexing_technique": "high_quality"
                },
                "description": "å®Œæ•´é…ç½®ï¼šè‡ªåŠ¨æ¨¡å¼+é«˜è´¨é‡ç´¢å¼•"
            },
            {
                "name": "æ˜¾å¼æŒ‡å®šæ®µè½æ¨¡å¼",
                "data": {
                    "name": file_name,
                    "process_rule": json.dumps({
                        "mode": "custom", 
                        "rules": {
                            "segmentation": {
                                "separator": "\\n\\n",
                                "max_tokens": 1000
                            }
                        }
                    })
                },
                "description": "æ˜¾å¼æŒ‡å®šæ®µè½åˆ†å‰²æ¨¡å¼"
            }
        ]
        
        results = []
        
        for i, strategy in enumerate(strategies):
            logger.info(f"\nğŸ”§ æµ‹è¯•ç­–ç•¥ {i+1}/{len(strategies)}: {strategy['name']}")
            logger.info(f"ğŸ“‹ æè¿°: {strategy['description']}")
            logger.info(f"âš™ï¸ é…ç½®: {json.dumps(strategy['data'], ensure_ascii=False)}")
            
            success, result = self._test_single_upload(file_path, config.PARENT_CHILD_KB_ID, strategy)
            results.append({
                "strategy": strategy['name'],
                "success": success,
                "result": result
            })
            
            if success:
                logger.info(f"âœ… ç­–ç•¥æˆåŠŸ: {strategy['name']}")
            else:
                logger.info(f"âŒ ç­–ç•¥å¤±è´¥: {strategy['name']}")
            
            # ç­–ç•¥é—´çŸ­æš‚å»¶è¿Ÿ
            time.sleep(2)
        
        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        self._print_test_summary(results, file_name)
        
        return results
    
    def _test_single_upload(self, file_path, knowledge_base_id, strategy):
        """æµ‹è¯•å•ä¸ªä¸Šä¼ ç­–ç•¥"""
        try:
            file_name = os.path.basename(file_path)
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(file_path)
            if file_size > 100 * 1024 * 1024:
                logger.warning(f"ğŸ“¦ æ–‡ä»¶è¿‡å¤§({file_size}å­—èŠ‚)ï¼Œè·³è¿‡æµ‹è¯•")
                return False, "æ–‡ä»¶è¿‡å¤§"
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'rb') as file:
                file_content = file.read()
            
            # ä½¿ç”¨BytesIO
            from io import BytesIO
            file_stream = BytesIO(file_content)
            
            # è·å–MIMEç±»å‹
            file_ext = os.path.splitext(file_name)[1].lower()
            mime_type = self._get_mime_type(file_ext)
            
            url = f"{config.DIFY_BASE_URL}/v1/datasets/{knowledge_base_id}/document/create-by-file"
            
            files = {'file': (file_name, file_stream, mime_type)}
            data = strategy['data']
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "User-Agent": "UploadTester/1.0"
            }
            
            logger.debug(f"ğŸŒ è¯·æ±‚URL: {url}")
            logger.debug(f"ğŸ“¤ è¯·æ±‚æ•°æ®: {data}")
            
            response = requests.post(
                url, 
                headers=headers, 
                files=files, 
                data=data, 
                timeout=config.API_TIMEOUT
            )
            
            if response.status_code in [200, 201]:
                result = response.json()
                logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ - æ–‡æ¡£ID: {result.get('id', 'æœªçŸ¥')}")
                
                # å°è¯•è·å–æ–‡æ¡£è¯¦æƒ…
                doc_info = self._get_document_info(knowledge_base_id, result.get('id'))
                
                return True, {
                    "document_id": result.get('id'),
                    "response": result,
                    "document_info": doc_info
                }
            else:
                error_msg = f"âŒ ä¸Šä¼ å¤±è´¥: {response.status_code} - {response.text}"
                logger.error(error_msg)
                
                # åˆ†æé”™è¯¯ç±»å‹
                error_analysis = self._analyze_upload_error(response)
                
                return False, {
                    "error_code": response.status_code,
                    "error_message": response.text,
                    "analysis": error_analysis
                }
                
        except requests.exceptions.Timeout:
            error_msg = "â° è¯·æ±‚è¶…æ—¶"
            logger.error(error_msg)
            return False, {"error": "è¯·æ±‚è¶…æ—¶"}
        except requests.exceptions.ConnectionError:
            error_msg = "ğŸŒ è¿æ¥é”™è¯¯"
            logger.error(error_msg)
            return False, {"error": "è¿æ¥é”™è¯¯"}
        except Exception as e:
            error_msg = f"ğŸ’¥ ä¸Šä¼ å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            return False, {"error": str(e)}
    
    def _get_mime_type(self, file_ext):
        """è·å–MIMEç±»å‹"""
        mime_types = {
            '.txt': 'text/plain',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.doc': 'application/msword',
            '.pdf': 'application/pdf',
            '.pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            '.csv': 'text/csv',
            '.md': 'text/markdown'
        }
        return mime_types.get(file_ext, 'application/octet-stream')
    
    def _analyze_upload_error(self, response):
        """åˆ†æä¸Šä¼ é”™è¯¯"""
        error_text = response.text.lower()
        analysis = []
        
        if "doc_form" in error_text:
            analysis.append("ğŸ“‹ æ–‡æ¡£æ ¼å¼é”™è¯¯ï¼šä¸Šä¼ é…ç½®ä¸çŸ¥è¯†åº“çš„åˆ†æ®µæ¨¡å¼ä¸åŒ¹é…")
            analysis.append("ğŸ’¡ å¯èƒ½åŸå› ï¼šçŸ¥è¯†åº“è®¾ç½®ä¸ºæ®µè½æ¨¡å¼ï¼Œä½†ä¸Šä¼ é…ç½®å°è¯•ä½¿ç”¨å…¨æ–‡æ¨¡å¼ï¼Œæˆ–åä¹‹")
        
        if "indexing_technique" in error_text:
            analysis.append("âš™ï¸ ç´¢å¼•æŠ€æœ¯é”™è¯¯")
            analysis.append("ğŸ’¡ å¯èƒ½åŸå› ï¼šçˆ¶å­æ¨¡å¼çŸ¥è¯†åº“å¿…é¡»ä½¿ç”¨é«˜è´¨é‡ç´¢å¼•")
        
        if "not found" in error_text:
            analysis.append("ğŸ” çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–APIå¯†é’¥æ— æƒé™")
        
        if "unauthorized" in error_text:
            analysis.append("ğŸ” è®¤è¯å¤±è´¥ï¼šè¯·æ£€æŸ¥APIå¯†é’¥")
        
        if "segmentation" in error_text:
            analysis.append("ğŸ“Š åˆ†æ®µè§„åˆ™é”™è¯¯")
            analysis.append("ğŸ’¡ å¯èƒ½åŸå› ï¼šåˆ†æ®µå‚æ•°ä¸çŸ¥è¯†åº“è®¾ç½®å†²çª")
        
        if not analysis:
            analysis.append("ğŸ”§ æœªçŸ¥é”™è¯¯ç±»å‹ï¼Œè¯·æ£€æŸ¥Dify APIæ–‡æ¡£")
        
        return analysis
    
    def _get_document_info(self, knowledge_base_id, document_id):
        """è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯"""
        if not document_id:
            return None
        
        try:
            url = f"{config.DIFY_BASE_URL}/v1/datasets/{knowledge_base_id}/documents/{document_id}"
            headers = {"Authorization": f"Bearer {self.api_key}"}
            
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"è·å–æ–‡æ¡£ä¿¡æ¯å¤±è´¥: {response.status_code}")
                return None
        except Exception as e:
            logger.warning(f"è·å–æ–‡æ¡£ä¿¡æ¯å¼‚å¸¸: {str(e)}")
            return None
    
    def _print_test_summary(self, results, file_name):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š ä¸Šä¼ æµ‹è¯•æ€»ç»“")
        logger.info("="*80)
        
        successful_strategies = [r for r in results if r['success']]
        failed_strategies = [r for r in results if not r['success']]
        
        logger.info(f"ğŸ“ æµ‹è¯•æ–‡ä»¶: {file_name}")
        logger.info(f"âœ… æˆåŠŸç­–ç•¥: {len(successful_strategies)}/{len(results)}")
        logger.info(f"âŒ å¤±è´¥ç­–ç•¥: {len(failed_strategies)}/{len(results)}")
        
        if successful_strategies:
            logger.info("\nğŸ¯ æˆåŠŸçš„ä¸Šä¼ ç­–ç•¥:")
            for result in successful_strategies:
                logger.info(f"  âœ“ {result['strategy']}")
                if 'document_id' in result['result']:
                    logger.info(f"    æ–‡æ¡£ID: {result['result']['document_id']}")
        
        if failed_strategies:
            logger.info("\nâš ï¸ å¤±è´¥çš„ä¸Šä¼ ç­–ç•¥åŠé”™è¯¯åˆ†æ:")
            for result in failed_strategies:
                logger.info(f"  âœ— {result['strategy']}")
                if 'analysis' in result['result']:
                    for analysis_line in result['result']['analysis']:
                        logger.info(f"    {analysis_line}")
        
        # ç»™å‡ºå»ºè®®
        logger.info("\nğŸ’¡ å»ºè®®:")
        if successful_strategies:
            best_strategy = successful_strategies[0]
            logger.info(f"æ¨èä½¿ç”¨ç­–ç•¥: '{best_strategy['strategy']}'")
            logger.info("åœ¨file_monitor_final.pyä¸­ä½¿ç”¨æ­¤ç­–ç•¥çš„é…ç½®")
        else:
            logger.info("âŒ æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥çŸ¥è¯†åº“è®¾ç½®")
            logger.info("ğŸ’¡ å»ºè®®æ£€æŸ¥:")
            logger.info("  1. çŸ¥è¯†åº“IDæ˜¯å¦æ­£ç¡®")
            logger.info("  2. APIå¯†é’¥æ˜¯å¦æœ‰æƒé™")
            logger.info("  3. DifyæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
            logger.info("  4. çŸ¥è¯†åº“çš„åˆ†æ®µæ¨¡å¼è®¾ç½®")
        
        logger.info("="*80)
    
    def get_knowledge_base_info(self, knowledge_base_id):
        """è·å–çŸ¥è¯†åº“ä¿¡æ¯"""
        try:
            url = f"{config.DIFY_BASE_URL}/v1/datasets/{knowledge_base_id}"
            headers = {"Authorization": f"Bearer {self.api_key}"}
            
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                kb_info = response.json()
                logger.info("ğŸ“‹ çŸ¥è¯†åº“ä¿¡æ¯:")
                logger.info(f"  åç§°: {kb_info.get('name', 'æœªçŸ¥')}")
                logger.info(f"  æè¿°: {kb_info.get('description', 'æ— æè¿°')}")
                logger.info(f"  æ–‡æ¡£æ•°é‡: {kb_info.get('document_count', 0)}")
                logger.info(f"  ç´¢å¼•æŠ€æœ¯: {kb_info.get('indexing_technique', 'æœªçŸ¥')}")
                logger.info(f"  åˆ›å»ºæ—¶é—´: {kb_info.get('created_at', 'æœªçŸ¥')}")
                return kb_info
            else:
                logger.error(f"è·å–çŸ¥è¯†åº“ä¿¡æ¯å¤±è´¥: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            logger.error(f"è·å–çŸ¥è¯†åº“ä¿¡æ¯å¼‚å¸¸: {str(e)}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª DifyçŸ¥è¯†åº“ä¸Šä¼ æ¨¡å¼æµ‹è¯•å·¥å…·")
    print("="*50)
    
    # æ£€æŸ¥å¿…è¦é…ç½®
    if not all([config.DIFY_BASE_URL, config.DATASET_API_KEY, config.PARENT_CHILD_KB_ID]):
        print("âŒ ç¯å¢ƒå˜é‡é…ç½®ä¸å®Œæ•´")
        print("è¯·æ£€æŸ¥ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        print(f"  DIFY_BASE_URL: {config.DIFY_BASE_URL}")
        print(f"  DIFY_API_KEY: {config.DATASET_API_KEY}")
        print(f"  PARENT_CHILD_KB_ID: {config.PARENT_CHILD_KB_ID}")
        return
    
    tester = UploadTester()
    
    # æ˜¾ç¤ºçŸ¥è¯†åº“ä¿¡æ¯
    print("\nğŸ” æ£€æŸ¥çŸ¥è¯†åº“ä¿¡æ¯...")
    kb_info = tester.get_knowledge_base_info(config.PARENT_CHILD_KB_ID)
    
    if not kb_info:
        print("âŒ æ— æ³•è·å–çŸ¥è¯†åº“ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    # è·å–æµ‹è¯•æ–‡ä»¶è·¯å¾„
    test_file = input("\nğŸ“ è¯·è¾“å…¥è¦æµ‹è¯•çš„æ–‡ä»¶è·¯å¾„ï¼ˆæˆ–ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤æµ‹è¯•æ–‡ä»¶ï¼‰: ").strip()
    
    if not test_file:
        # ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„æµ‹è¯•æ–‡ä»¶
        default_files = ['test.docx', 'test.pdf', 'test.txt', '1.docx']
        for file in default_files:
            if os.path.exists(file):
                test_file = file
                break
        
        if not test_file:
            print("âŒ æœªæ‰¾åˆ°é»˜è®¤æµ‹è¯•æ–‡ä»¶ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šæ–‡ä»¶è·¯å¾„")
            return
    
    if not os.path.exists(test_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        return
    
    print(f"ğŸ“‚ ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {test_file}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(test_file)} å­—èŠ‚")
    
    # å¼€å§‹æµ‹è¯•
    print("\nğŸš€ å¼€å§‹ä¸Šä¼ æµ‹è¯•...")
    results = tester.test_upload_modes(test_file)
    
    # ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶
    result_file = f"upload_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            "test_time": datetime.now().isoformat(),
            "test_file": test_file,
            "knowledge_base_id": config.PARENT_CHILD_KB_ID,
            "results": results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    print("ğŸ¯ æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()